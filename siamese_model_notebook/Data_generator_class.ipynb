{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a548d08-57d5-4252-990d-62c80dfa473b",
   "metadata": {},
   "source": [
    "# Data-Generator Class \n",
    "\n",
    "So far we have been working on training the Siamese network. \n",
    "we encouter the problem that loading all the images on memory \n",
    "ruins our notebook environment. since we have a large \n",
    "dataset that has more than 4 million images we have to create \n",
    "a process to load the images by means of data so, we \n",
    "can save memory and so on. \n",
    "\n",
    "we cannot exceed the quota of 32Gb in the memory of the \n",
    "GPU. so we are going to use a method for loading \n",
    "dynamically by batch the images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882402e8-bdaa-48b7-851f-745d7d3e02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 10:40:51.578229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
      "2023-08-25 10:40:51.579809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-2.1/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c13207-0eb4-4e96-b83a-9d0829665629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9470f117-73fd-47c8-bbb9-43518841b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have an example of a data generator using triplets\n",
    "# wee need to adapt it to our code for not loading all the images into memory \n",
    "#so we can use the GPU, we need to balance the memory of the GPU \n",
    "# we only have 32 GB of memory on the GPU. \n",
    "# only the model usese 9GB of space in the memory, so lets explore this solution \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class TripletDataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, csv_file, output_size, shuffle=False, batch_size=10):\n",
    "        #we initialize the class with some attributes\n",
    "        #we can ommit the base_dir since our triplets have the real path \n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        #self.base_dir = base_dir\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.df) / self.batch_size)\n",
    "    \n",
    "    #we have our custom load image so, we will avoid the \n",
    "    #use of cv2 \n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        #path = \"/content/drive/MyDrive/C-Minds phase 3/data/\"\n",
    "        imsize = 224\n",
    "        image = load_img(img_path)\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        return image/ 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #getting the image, here we have to  be carefull to understand \n",
    "        #what is happenning inside the class and the function. \n",
    "        \n",
    "        X_anchor = np.empty((self.batch_size, *self.output_size, 3))\n",
    "        X_positive = np.empty((self.batch_size, *self.output_size, 3))\n",
    "        X_negative = np.empty((self.batch_size, *self.output_size, 3))\n",
    "        \n",
    "        #X_anchor = []\n",
    "        #X_positive = []\n",
    "        #X_negative = []\n",
    "\n",
    "        indices = self.indices[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "\n",
    "        for i, data_index in enumerate(indices):\n",
    "            anchor_path = self.df.iloc[data_index, 1]\n",
    "            positive_path = self.df.iloc[data_index, 2]\n",
    "            negative_path = self.df.iloc[data_index, 3]\n",
    "            \n",
    "            #to see how the class works lets ouput the path of the image \n",
    "            X_anchor[i] = self.load_image(anchor_path)\n",
    "            X_positive[i] = self.load_image(positive_path)\n",
    "            X_negative[i] = self.load_image(negative_path)\n",
    "            \n",
    "        #change to zero the ones \n",
    "        return [X_anchor, X_positive, X_negative],np.ones(len(X_anchor))  # No labels for triplets\n",
    "\n",
    "# Example usage\n",
    "csv_file = \"csvs/pro_big_triplets.csv\"\n",
    "#base_dir = \"path_to_images_directory\"\n",
    "output_size = (224, 224)  # Adjust as needed\n",
    "batch_size = 3000\n",
    "\n",
    "data_generator = TripletDataGenerator(csv_file, output_size, shuffle=True, batch_size=batch_size)\n",
    "batch_inputs, _ = data_generator[0]  # Get a batch of triplet inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699e76f1-33ee-4fe4-81b4-57daba96b4fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126339/412664689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c44ce-cc10-434e-a41d-f1ec2dcd1473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de55830-0863-4d4d-9fd6-29359962d1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595bcc4-d497-421f-8928-d0749cc98c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf39a2-55b1-441d-aac7-11aac012d3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a3432-4433-4b26-9a00-21bd49b5d7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f678e64-0457-43c0-a8b1-a3ea2c94e550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9cefc0-8395-4a69-b2bd-794dae50a65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs, _ = data_generator[0]\n",
    "len(batch_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bd54396-caaf-4972-9ec9-4b47d0d933b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crop_pro_nat/JM015 Monotas/JM015 Monotas_original_elzapotal_ZAP06B06_2013_R5V_Panthera onca.JPG_9f1e4c3e-a8b3-4087-9538-b434028b1af0.JPG_left_top.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241c5ba8-df44-4743-aaed-7b997fde87ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crop_pro_nat/JM015 Monotas/elzapotal_ZAP06CUDE06_2013_R5_441 JM-12.JPG_cropped_img.jpg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc1f0b1e-37b1-4bcd-af87-e9b8726ce5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crop_pro_nat/JH010 Sarabi/JH010 Sarabi_original_439851.668_2363207.75_2016 (1).JPG_83acd3c8-5a3e-4906-ad94-88e96a2772de.JPG_left_bottom.jpg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295a866-2f88-4d6a-9b6e-6e114fab4c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33d4cb-80de-447c-93a3-0b6e8d357bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-2.1",
   "language": "python",
   "name": "tensorflow-2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
